{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1t8N0hrkgIC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB1qth6Akmcx"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor([[1,2], [3,2], [3,7], [1,1], [1,0]])\n",
        "y_train = torch.FloatTensor([[4], [8], [23], [1], [-2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTx_lY01kmk4"
      },
      "outputs": [],
      "source": [
        "w = torch.rand(2,1) # w,b 초기화\n",
        "b = torch.rand(1,1)\n",
        "lr = 0.01 # learing rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Deikh3iEkp8V",
        "outputId": "70f1f422-8cb3-4ce8-ec0c-eb6e69df9c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0, cost: 55.501091, w: tensor([0.3970, 1.4396]), b: tensor([[0.4393]])\n",
            "epoch: 100, cost: 1.756306, w: tensor([0.4889, 3.1932]), b: tensor([[-1.1835]])\n",
            "epoch: 200, cost: 0.878220, w: tensor([0.8282, 3.2030]), b: tensor([[-2.0422]])\n",
            "epoch: 300, cost: 0.451020, w: tensor([1.1499, 3.1528]), b: tensor([[-2.6034]])\n",
            "epoch: 400, cost: 0.231784, w: tensor([1.3894, 3.1104]), b: tensor([[-2.9996]])\n",
            "epoch: 500, cost: 0.119118, w: tensor([1.5622, 3.0792]), b: tensor([[-3.2829]])\n",
            "epoch: 600, cost: 0.061217, w: tensor([1.6861, 3.0568]), b: tensor([[-3.4859]])\n",
            "epoch: 700, cost: 0.031460, w: tensor([1.7750, 3.0407]), b: tensor([[-3.6315]])\n",
            "epoch: 800, cost: 0.016168, w: tensor([1.8387, 3.0292]), b: tensor([[-3.7358]])\n",
            "epoch: 900, cost: 0.008309, w: tensor([1.8844, 3.0209]), b: tensor([[-3.8106]])\n",
            "epoch: 1000, cost: 0.004270, w: tensor([1.9171, 3.0150]), b: tensor([[-3.8642]])\n",
            "epoch: 1100, cost: 0.002195, w: tensor([1.9406, 3.0108]), b: tensor([[-3.9027]])\n",
            "epoch: 1200, cost: 0.001128, w: tensor([1.9574, 3.0077]), b: tensor([[-3.9302]])\n",
            "epoch: 1300, cost: 0.000580, w: tensor([1.9695, 3.0055]), b: tensor([[-3.9500]])\n",
            "epoch: 1400, cost: 0.000298, w: tensor([1.9781, 3.0040]), b: tensor([[-3.9641]])\n",
            "epoch: 1500, cost: 0.000153, w: tensor([1.9843, 3.0028]), b: tensor([[-3.9743]])\n",
            "epoch: 1600, cost: 0.000079, w: tensor([1.9887, 3.0020]), b: tensor([[-3.9816]])\n",
            "epoch: 1700, cost: 0.000040, w: tensor([1.9919, 3.0015]), b: tensor([[-3.9868]])\n",
            "epoch: 1800, cost: 0.000021, w: tensor([1.9942, 3.0010]), b: tensor([[-3.9905]])\n",
            "epoch: 1900, cost: 0.000011, w: tensor([1.9959, 3.0008]), b: tensor([[-3.9932]])\n",
            "epoch: 2000, cost: 0.000005, w: tensor([1.9970, 3.0005]), b: tensor([[-3.9951]])\n",
            "epoch: 2100, cost: 0.000003, w: tensor([1.9979, 3.0004]), b: tensor([[-3.9965]])\n",
            "epoch: 2200, cost: 0.000001, w: tensor([1.9985, 3.0003]), b: tensor([[-3.9975]])\n",
            "epoch: 2300, cost: 0.000001, w: tensor([1.9989, 3.0002]), b: tensor([[-3.9982]])\n",
            "epoch: 2400, cost: 0.000000, w: tensor([1.9992, 3.0001]), b: tensor([[-3.9987]])\n",
            "epoch: 2500, cost: 0.000000, w: tensor([1.9994, 3.0001]), b: tensor([[-3.9991]])\n",
            "epoch: 2600, cost: 0.000000, w: tensor([1.9996, 3.0001]), b: tensor([[-3.9993]])\n",
            "epoch: 2700, cost: 0.000000, w: tensor([1.9997, 3.0001]), b: tensor([[-3.9995]])\n",
            "epoch: 2800, cost: 0.000000, w: tensor([1.9998, 3.0000]), b: tensor([[-3.9997]])\n",
            "epoch: 2900, cost: 0.000000, w: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n",
            "epoch: 3000, cost: 0.000000, w: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3001): # 반복횟수\n",
        "  w.requires_grad_(True)  # w,b의 기울기 구하기 설정\n",
        "  b.requires_grad_(True)\n",
        "  hypothesis = torch.mm(x_train, w) + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2) # mean = 평균 모든 오차에 대해서 계산\n",
        "  # 루트는 안해도 무방해서 안한듯함\n",
        "  cost.backward()\n",
        "  with torch.no_grad() as grd : # 그래디언트 추적 x 불필요한 계산이기 떄문\n",
        "    w = w - lr * w.grad\n",
        "    b = b - lr * b.grad\n",
        "    if(epoch % 100 == 0): # 결과 출력\n",
        "      print( 'epoch: {}, cost: {:.6f}, w: {}, b: {}'.format(epoch,cost.item(), w.squeeze(), b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l11epKSiofU4",
        "outputId": "e9a4bd89-bc8e-4647-f5b8-8572635ef5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35.99983215332031\n"
          ]
        }
      ],
      "source": [
        "x_test = torch.FloatTensor([[5,10]]) # x가 5,10일때\n",
        "test_result = torch.mm(x_test, w) + b\n",
        "print(test_result.item())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
